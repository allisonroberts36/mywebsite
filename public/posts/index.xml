<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>data projects on Allison Roberts</title>
    <link>/posts/</link>
    <description>Recent content in data projects on Allison Roberts</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 Feb 2018 12:21:57 -0500</lastBuildDate>
    
	<atom:link href="/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Mapping Hospitals Using a Shiny App</title>
      <link>/posts/visualizing-hospital-networks/</link>
      <pubDate>Thu, 19 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/visualizing-hospital-networks/</guid>
      <description>Mapping Hospitals My goal was to build a highly interactive, informative, and easy-to-understand map of hospitals in the United States. I went through a lot of methods to create this final product, but landed on a combination of Shiny, ggplot2, and plotly to create my final map. The project looks like this: 
This piece was a part of a larger article on hospitals, published on Canopy.
Below, I’ll walk you through the creation of the final map.</description>
    </item>
    
    <item>
      <title>Visualizing Hospital Networks</title>
      <link>/posts/visualizing-hospital-networks/</link>
      <pubDate>Wed, 14 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/posts/visualizing-hospital-networks/</guid>
      <description>##Visualizing a Network My goal is to build an interactive network model that jiggles and is generally fun. I ended up exporting the final product into Shiny, and it looks like this: 
Below, I’ll show you how I created this project, starting with a similarity matrix of hospital websites and a list of hospital attributes. To see how I created the similarity matrix, check out Part One.</description>
    </item>
    
    <item>
      <title>Comparing Hospital Websites</title>
      <link>/posts/comparing-hospital-websites/</link>
      <pubDate>Tue, 13 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/posts/comparing-hospital-websites/</guid>
      <description>This RStudio project proposes a strategy to compare hospital websites using their main menus. Main menus are relatively consistent across sites, but also reflect active curating by web developers. They tell us what the hospital offers, and how it feels those offerings should be advertised.
This project starts with a dataframe that has a “main menu text” variable. This dataframe was built using Python’s BeautifulSoup package, where a list of hospital URLs were scraped for a variety of text variables.</description>
    </item>
    
    <item>
      <title>Scraping Websites</title>
      <link>/posts/scraping-websites/</link>
      <pubDate>Tue, 13 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/posts/scraping-websites/</guid>
      <description>The following code scrapes a list of websites using Python. Most of the explanations are provided within the code as comments.
We first import a few packages to assist with scraping, and set the working directory.
#Import Packages import requests from bs4 import BeautifulSoup import lxml import os import re import pandas as pd import numpy as np from urllib.parse import urljoin #Set Working Directory os.getcwd() os.chdir(&amp;#34;Your/File/Path/Here&amp;#34;) Once the environment is set up, I wrote a variety of functions to conduct different type of scrapes.</description>
    </item>
    
  </channel>
</rss>